{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b58acc8f-0ede-425b-8a6e-ffafcb80e5e2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "746b35d6-f5c0-44d3-9fac-2f39398b800b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Function to read data from a file\n",
    "def read_data(file_location):\n",
    "    df = pd.read_csv(file_location)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b0464e1-4d9e-410a-8d43-7eb92efa5642",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def df_one_day(pandas_df_to_plot,year_to_plot,month_to_plot, day_to_plot):\n",
    "    p_one_day = pandas_df_to_plot[(pandas_df_to_plot.index.day == day_to_plot) & (pandas_df_to_plot.index.year == year_to_plot) & (pandas_df_to_plot.index.month == month_to_plot)]\n",
    "    return p_one_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "06e34aed-4527-4a2b-aea5-2bc05ee1d70c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def df_one_month(pandas_df_to_plot,year_to_plot,month_to_plot, day_to_plot):\n",
    "    p_one_day = pandas_df_to_plot[(pandas_df_to_plot.index.day == day_to_plot) & (pandas_df_to_plot.index.year == year_to_plot) & (pandas_df_to_plot.index.month == month_to_plot)]\n",
    "    return p_one_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "186df50d-6cf8-4887-abc6-687a3cc69534",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def plot_one_day(pandas_df_to_plot,year_to_plot,month_to_plot, day_to_plot):\n",
    "    p_to_plot = df_one_day(pandas_df_to_plot,year_to_plot,month_to_plot, day_to_plot)\n",
    "    plt.rcParams[\"figure.figsize\"] = (40,3)\n",
    "    plt.plot(p_to_plot)\n",
    "    plt.show()\n",
    "    print(\"Plotting: year = \", year_to_plot, \" month = \", month_to_plot, \" day = \", day_to_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "43cfd7a9-c63d-48f9-9512-e4375dac058f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def plot_one_month(pandas_df_to_plot,year_to_plot,month_to_plot):\n",
    "    days_from_month = pandas_df_to_plot[(pandas_df_to_plot.index.year == year_to_plot) & (pandas_df_to_plot.index.month == month_to_plot)].index.day.unique().values\n",
    "    for day in days_from_month:\n",
    "        plot_one_day(pandas_df_to_plot, year_to_plot,month_to_plot, day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e6e6be8b-2832-4bae-b2c8-83f1cd0a278c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def print_max_freq_month(df):\n",
    "    door_open_monthly = df.resample('M').sum()\n",
    "    max_month_year = door_open_monthly[door_open_monthly.value == door_open_monthly.value.max()].index.year[0]\n",
    "    max_month_month = door_open_monthly[door_open_monthly.value == door_open_monthly.value.max()].index.month[0]\n",
    "    print('Year with max door opening:', max_month_year)\n",
    "    print('Month with max door opening:', max_month_month)\n",
    "    plot_one_month(df,max_month_year,max_month_month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ea47197b-52a9-40ad-9b82-145e84dc4753",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_all_months(df, year):\n",
    "    return df[(df.index.year == year)].index.month.unique().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2f5895be-38be-4fb7-95a2-6dc3356651dd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_all_years(df):\n",
    "    return df.index.year.unique().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "adca1b03-b2a1-42ec-b591-c3a610567eef",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def plot_one_year(df, year):\n",
    "    all_months = get_all_months(df, year)\n",
    "    for month in all_months:\n",
    "        plot_one_month(df, year, month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "773b69c5-aebf-4cef-8cd3-d5ea6f73f430",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def show_all_years(df):\n",
    "    all_years = get_all_years(df)\n",
    "    for year in all_years:\n",
    "        plot_one_year(df, year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5842e2c5-a7bf-4d2d-9ea9-3db01d922144",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Function to preprocess and clean data\n",
    "def preprocess_data(df, aggregation='H', ws=24, number_of_predicted_days=2):\n",
    "\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    df.drop_duplicates(subset=['source_ts'], inplace=True)\n",
    "\n",
    "    datetime_series = pd.to_datetime(df['source_ts'])\n",
    "    datetime_index = pd.DatetimeIndex(datetime_series.values)\n",
    "    df=df.set_index(datetime_index)\n",
    "    df.drop('source_ts',axis=1,inplace=True)\n",
    "\n",
    "    df=df.asfreq(freq='S', method='ffill')\n",
    "\n",
    "    lastDay = df.index[-1].strftime('%Y-%m-%d')\n",
    "    df = df.loc[:lastDay].iloc[:-1 , :]\n",
    "    df\n",
    "\n",
    "    prediction_in_future_time = ws * number_of_predicted_days\n",
    "    \n",
    "    df_resampled = df.resample(aggregation).sum()\n",
    "    df_resampled\n",
    "    \n",
    "    year_to_plot = df.index[-1].year\n",
    "    month_to_plot = df.index[-1].month\n",
    "    day_to_plot = df.index[-1].day\n",
    "\n",
    "    plot_one_day(df, year_to_plot, month_to_plot, day_to_plot)\n",
    "\n",
    "    plot_one_day(df_resampled, year_to_plot, month_to_plot, day_to_plot)\n",
    "\n",
    "    df = df_resampled\n",
    "    n_splits = 4\n",
    "    test_size = 48\n",
    "    total_len = len ( df )\n",
    "    fold_size = (total_len - test_size) // n_splits\n",
    "    \n",
    "    tscv = TimeSeriesSplit ( n_splits = n_splits)\n",
    "    splits = []\n",
    "    for train_index, test_index in tscv.split(df):\n",
    "        test_indices = np.arange(test_index[0], test_index[0] + test_size)\n",
    "        train_indices = np.arange(0, test_indices[0])\n",
    "        splits.append((train_indices[0], train_indices[-1], test_indices[0], test_indices[-1]))\n",
    "\n",
    "    return df_resampled, splits, n_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "45bce702-d1a8-46ae-98c4-b55ce7556a58",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Function to create an LSTM model\n",
    "def create_rnn_model(shape):\n",
    "    Model_P = Sequential()\n",
    "    Model_P.add(LSTM(units = 64,  return_sequences = True, input_shape = (shape, 1)))\n",
    "    Model_P.add(Dropout(0.2))\n",
    "    Model_P.add(LSTM(units=64, return_sequences=True)) \n",
    "    Model_P.add(Dropout(0.2)) \n",
    "    Model_P.add(LSTM(units=64, return_sequences=True))\n",
    "    Model_P.add(Dropout(0.2))         \n",
    "    Model_P.add(LSTM(units=64))\n",
    "    Model_P.add(Dropout(0.2)) \n",
    "    Model_P.add(Dense(units=1))\n",
    "    return Model_P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b5dadb2-a81d-4238-ac32-e453034f9779",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Function to train the LSTM model\n",
    "def train_lstm_model(model, x_train, y_train, epochs=15, batch_size=32):\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e9a813ce-5c8b-4958-bb36-fa4d032d5594",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Function to make predictions using the trained model\n",
    "def make_predictions(model, batch_one, prediction_in_future_time):\n",
    "    prediction_test = []\n",
    "    batch_new = batch_one.reshape((1, ws, 1))\n",
    "    \n",
    "    for _ in range(prediction_in_future_time):\n",
    "        first_pred = model.predict(batch_new)[0]\n",
    "        prediction_test.append(first_pred)\n",
    "        batch_new = np.append(batch_new[:, 1:, :], [[first_pred]], axis=1)\n",
    "\n",
    "    return np.array(prediction_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "213b7b50-214a-4c81-a996-80e8ccf5ea4d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Function to evaluate the model\n",
    "def evaluate_model(test_set, predictions):\n",
    "    rmse = np.sqrt(mean_squared_error(test_set, predictions))\n",
    "    rsquare = r2_score(test_set, predictions)\n",
    "    return rmse, rsquare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9da07a55-18fe-4ccd-a737-f4571bf32300",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Function to compute the forecast bias\n",
    "def compute_forecast_bias(test_set, predictions):\n",
    "    differences = [predicted - actual for predicted, actual in zip(predictions, test_set)]\n",
    "    bias = sum(differences) / len(differences)\n",
    "    return bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "96086dc9-a24d-47de-9a55-e182831611c8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Function to compute the forecast interval coverage\n",
    "def compute_forecast_interval_coverage(test_set, predictions, rmse):\n",
    "    forecasted_intervals = [(lower, upper) for lower, upper in zip(predictions - 1.96 * rmse, predictions + 1.96 * rmse)]\n",
    "    num_within_the_interval = sum((lower <= actual <= upper) for actual, (lower, upper) in zip (test_set, forecasted_intervals))\n",
    "    total_observations = len(test_set)\n",
    "    fic = num_within_the_interval / total_observations * 100\n",
    "    return fic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "24bb8cf1-d7bc-4bfb-9a6c-d8d893163bc3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def compute_prediction_direction_accuracy(test_set, predictions):\n",
    "    correct_directions = 0\n",
    "    for i in range(1, len(predictions)):\n",
    "        pred_change = predictions[i] - predictions[i-1]\n",
    "        actual_change = test_set[i] - test_set[i-1]\n",
    "        if(pred_change > 0 and actual_change > 0) or (pred_change > 0 and actual_change < 0) or (pred_change == 0 and actual_change == 0):\n",
    "            correct_directions += 1\n",
    "    pda = (correct_directions / (len(predictions) - 1)) * 100\n",
    "    return pda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f424d6d4-ed52-4e98-8118-d21bccef0ffa",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# # Function to plot the actual vs predicted values\n",
    "def plot_results(test_set, predictions):\n",
    "    plt.rcParams[\"figure.figsize\"] = (40,3)\n",
    "    plt.plot(test_set, color='green', label='Actual value')\n",
    "    plt.plot(predictions, color='orange', label='Predicted value')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "86082ac2-a207-4361-9a71-0fc1edd81e41",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Function to create input sequences for training the LSTM model\n",
    "def create_input_sequences(data, ws):\n",
    "    x_train, y_train = [], []\n",
    "\n",
    "    for i in range(ws, len(data)):\n",
    "        x_train.append(data[i-ws:i, 0:1])\n",
    "        y_train.append(data[i, 0])\n",
    "    \n",
    "    return np.array(x_train), np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4f3f0bdd-72f5-4c5c-b94d-ad6f2487e0aa",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Main function\n",
    "def main(file_location):\n",
    "    df = read_data(file_location)\n",
    "\n",
    "    df_resampled, splits, n_splits = preprocess_data(df)\n",
    "\n",
    "    rmse_values = []\n",
    "    r_squared_values = []\n",
    "    for split in range(n_splits):\n",
    "        train_start, train_end, test_start, test_end = splits[split]\n",
    "        training_set = df_resampled[train_start:train_end + 1].values\n",
    "        test_set = df_resampled[test_start:test_end + 1].values\n",
    "        sc = MinMaxScaler(feature_range=(0,1))\n",
    "        training_set_scaled = sc.fit_transform(training_set)\n",
    "        x_train, y_train = create_input_sequences(training_set_scaled, ws)\n",
    "        model = create_rnn_model(x_train.shape[1])\n",
    "        model = train_lstm_model(model, x_train, y_train)\n",
    "        batch_one = training_set_scaled[-ws:]\n",
    "        prediction_in_future_time = test_end - test_start + 1\n",
    "        prediction = make_predictions(model, batch_one, prediction_in_future_time)\n",
    "        prediction = sc.inverse_transform(prediction)\n",
    "        rmse, rsquare = evaluate_model(test_set, prediction)\n",
    "        rmse_values.append(rmse)\n",
    "        r_squared_values.append(rsquare)\n",
    "        plot_results(test_set, prediction)\n",
    "\n",
    "    print(\"RMSE values= \",rmse_values)\n",
    "    print(\"R2 values= \", r_squared_values)\n",
    "\n",
    "    print(\"Average RMSE: \", np.mean(rmse_values))\n",
    "    print(\"Average R2: \", np.mean(r_squared_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "deef3a5b-a7dd-43cc-b454-0185e44ee1fc",
     "showTitle": false,
     "title": ""
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ws = 24\n",
    "prediction_in_future_time = ws * 2\n",
    "main(\"./testData/Dataset1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "42b29f24-3490-42b1-bc3f-c5589f57ae68",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "LSTM_Tuned_TimeSeriesSplit",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
