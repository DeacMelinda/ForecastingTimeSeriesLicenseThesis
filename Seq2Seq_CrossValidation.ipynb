{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2669286e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Model\n",
    "from keras.layers import LSTM, Input, Dense, LSTMCell, RNN, Bidirectional, Concatenate\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ad7c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read data from a file\n",
    "def read_data(file_location):\n",
    "    df = pd.read_csv(file_location)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f758c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess and clean data\n",
    "def preprocess_data(df, aggregation='H', ws=24, number_of_predicted_days=2):\n",
    "\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    df.drop_duplicates(subset=['source_ts'], inplace=True)\n",
    "\n",
    "    datetime_series = pd.to_datetime(df['source_ts'])\n",
    "    datetime_index = pd.DatetimeIndex(datetime_series.values)\n",
    "    df=df.set_index(datetime_index)\n",
    "    df.drop('source_ts',axis=1,inplace=True)\n",
    "\n",
    "    df=df.asfreq(freq='S', method='ffill')\n",
    "\n",
    "    lastDay = df.index[-1].strftime('%Y-%m-%d')\n",
    "    df = df.loc[:lastDay].iloc[:-1 , :]\n",
    "    df\n",
    "\n",
    "    prediction_in_future_time = ws * number_of_predicted_days\n",
    "    \n",
    "    df_resampled = df.resample(aggregation).sum()\n",
    "    df_resampled\n",
    "\n",
    "    df = df_resampled\n",
    "    n_splits = 4\n",
    "    test_size = 48\n",
    "    total_len = len ( df )\n",
    "    fold_size = (total_len - test_size) // n_splits\n",
    "    tscv = TimeSeriesSplit ( n_splits = n_splits)\n",
    "    splits = []\n",
    "    for train_index, test_index in tscv.split(df):\n",
    "        test_indices = np.arange(test_index[0], test_index[0] + test_size)\n",
    "        train_indices = np.arange(0, test_indices[0])\n",
    "        splits.append((train_indices[0], train_indices[-1], test_indices[0], test_indices[-1]))\n",
    "\n",
    "    return df_resampled, splits, n_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d17829",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(no_input_features=1, no_output_features=1, layers=[6]):\n",
    "    \n",
    "    ## Encoder\n",
    "    encoder_inputs = Input(shape=(None, no_input_features))\n",
    "    lstm_cells = [LSTMCell(hidden_dim) for hidden_dim in layers]\n",
    "    encoder = RNN(lstm_cells, return_state=True)\n",
    "    encoder_outputs_and_states = encoder(encoder_inputs)\n",
    "    encoder_states = encoder_outputs_and_states[1:]\n",
    "    \n",
    "    ## Decoder\n",
    "    decoder_inputs = Input(shape=(None, no_output_features))\n",
    "    decoder_cells = [LSTMCell(hidden_dim) for hidden_dim in layers]\n",
    "    initial_states = encoder_states\n",
    "        \n",
    "    decoder_lstm = RNN(decoder_cells, return_sequences=True, return_state=True)\n",
    "\n",
    "    decoder_outputs_and_states = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "    decoder_outputs = decoder_outputs_and_states[0]\n",
    "\n",
    "    decoder_dense = Dense(no_output_features, activation='relu') \n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    \n",
    "    model = Model([encoder_inputs,decoder_inputs], decoder_outputs)\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a158e003",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_input_sequences(data, ws):\n",
    "    x_train, y_train = [], []\n",
    "\n",
    "    for i in range(ws, len(data)-ws-1):\n",
    "        x_train.append(data[i-ws:i, 0:1])\n",
    "        y_train.append(data[i+1:i+1+ws, 0:1])\n",
    "    \n",
    "    return np.array(x_train), np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339fee82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_dataset, epochs=60, batch_size=32):\n",
    "    \n",
    "    model.compile(Adam(), loss='mean_squared_error')\n",
    "    \n",
    "    input_sequence, output_sequence = create_input_sequences(train_dataset, 24)\n",
    "\n",
    "    encoder_input = input_sequence\n",
    "    decoder_target = output_sequence\n",
    "    decoder_input = np.zeros(decoder_target.shape)\n",
    "    \n",
    "    history = model.fit([encoder_input, decoder_input], decoder_target,\n",
    "                       batch_size=batch_size,\n",
    "                       epochs=epochs,\n",
    "                       validation_split=0.1,\n",
    "                       shuffle=False)\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb92a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(model, initial_batch, input_len=24, output_len=24, ws=24, prediction_in_future_time=48):\n",
    "    prediction_test = []\n",
    "    batch = []\n",
    "    batch = np.array([initial_batch[-ws:, 0:1]])  \n",
    "    print(batch.shape)\n",
    "    \n",
    "    for _ in range(2):\n",
    "        input_seq_test = batch\n",
    "        element = np.array([[[0.]]]) \n",
    "        decoder_input_test = np.stack([element]*24, axis=1)\n",
    "        prediction = model.predict([input_seq_test, decoder_input_test])[0]\n",
    "        \n",
    "        print(prediction)\n",
    "\n",
    "        batch = np.array([np.append(batch[0,24:], prediction, axis=0)])\n",
    "        \n",
    "        prediction_test.append(prediction)\n",
    "        \n",
    "    return np.array(prediction_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9d6988",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(test_set, predictions):\n",
    "    plt.rcParams[\"figure.figsize\"] = (40,3)\n",
    "    plt.plot(test_set, color='green', label='Actual value')\n",
    "    plt.plot(predictions, color='orange', label='Predicted value')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608a4025",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_prediction_direction_accuracy(test_set, predictions):\n",
    "    correct_directions = 0\n",
    "    for i in range(1, len(predictions)):\n",
    "        pred_change = predictions[i] - predictions[i-1]\n",
    "        actual_change = test_set[i] - test_set[i-1]\n",
    "        if(pred_change > 0 and actual_change > 0) or (pred_change > 0 and actual_change < 0) or (pred_change == 0 and actual_change == 0):\n",
    "            correct_directions += 1\n",
    "    pda = (correct_directions / (len(predictions) - 1)) * 100\n",
    "    return pda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b30a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute the forecast interval coverage\n",
    "def compute_forecast_interval_coverage(test_set, predictions, rmse):\n",
    "    forecasted_intervals = [(lower, upper) for lower, upper in zip(predictions - 1.96 * rmse, predictions + 1.96 * rmse)]\n",
    "    num_within_the_interval = sum((lower <= actual <= upper) for actual, (lower, upper) in zip (test_set, forecasted_intervals))\n",
    "    total_observations = len(test_set)\n",
    "    fic = num_within_the_interval / total_observations * 100\n",
    "    return fic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8210eacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute the forecast bias\n",
    "def compute_forecast_bias(test_set, predictions):\n",
    "    differences = [predicted - actual for predicted, actual in zip(predictions, test_set)]\n",
    "    bias = sum(differences) / len(differences)\n",
    "    return bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f61c683",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(file_location):\n",
    "    \n",
    "    df = read_data(file_location)\n",
    "    \n",
    "    df_resampled, splits, n_splits = preprocess_data(df)\n",
    "    \n",
    "    rmse_values=[]\n",
    "    r_squared_values=[]\n",
    "    \n",
    "    for split in range(n_splits):\n",
    "        train_start, train_end, test_start, test_end = splits[split]\n",
    "        \n",
    "        training_set = df_resampled[train_start:train_end+1].values\n",
    "        test_set = df_resampled[test_start:test_end+1].values\n",
    "    \n",
    "        sc = MinMaxScaler(feature_range=(0, 1))\n",
    "        training_set_scaled = sc.fit_transform(training_set)\n",
    "    \n",
    "        model = create_model(layers=[64])\n",
    "        model = train_model(model, train_dataset=training_set_scaled, epochs=60)\n",
    "        print(test_set)\n",
    "        \n",
    "        plt.rcParams[\"figure.figsize\"] = (40,3)\n",
    "        plt.plot(test_set)\n",
    "        plt.show()\n",
    "        batch_init = training_set_scaled[-ws:]\n",
    "        predictions = make_predictions(model, batch_init)\n",
    "    \n",
    "        merged_predictions = [item for sublist in predictions for item in sublist]\n",
    "        predictions = [[item.item()] for item in merged_predictions]\n",
    "\n",
    "        predictions = sc.inverse_transform(predictions)\n",
    "\n",
    "        rmse, rsquare = evaluate_model(test_set, predictions)\n",
    "        rmse_values.append(rmse)\n",
    "        r_squared_values.append(rsquare)\n",
    "        \n",
    "    print(\"RMSE values= \",rmse_values)\n",
    "    print(\"R2 values= \", r_squared_values)\n",
    "\n",
    "    print(\"Average RMSE: \", np.mean(rmse_values))\n",
    "    print(\"Average R2: \", np.mean(r_squared_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a18cffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate the model\n",
    "def evaluate_model(test_set, predictions):\n",
    "    rmse = np.sqrt(mean_squared_error(test_set, predictions))\n",
    "    rsquare = r2_score(test_set, predictions)\n",
    "    return rmse, rsquare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22751646",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ws = 24\n",
    "prediction_in_future_time = ws * 2\n",
    "main(\"./testData/Dataset1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b540ca56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
